#!/bin/bash

HADOOP_DIR=/home/ubuntu/hadoop-3.3.6
PROJECT_DIR=/home/ubuntu/DE1-Project
HDFS_BASEDIR=/user/ubuntu

usage() {
	echo "Usage: $0 [-h] <subcommand> [options]"
	echo ""
	echo "Subcommands:"
	echo "  build - Builds Jar file for MapReduce jobs"
	echo "  start - Starts Hadoop cluster "
	echo "  stop - Stops Hadoop cluster"
	echo "  runjob - Runs MapReduce job"
	echo ""
	echo "Options:"
	echo "  -h, --help   Display this help message"
	exit 1
}

do_build() {
	javac -cp `$HADOOP_DIR/bin/hadoop classpath` SubredditCount.java
	jar -cvf subredditcount.jar *SubredditCount*.class
}

do_start() {
	$HADOOP_DIR/sbin/start-dfs.sh
	$HADOOP_DIR/sbin/start-yarn.sh
}

do_stop() {
	$HADOOP_DIR/sbin/stop-dfs.sh
	$HADOOP_DIR/sbin/stop-yarn.sh
}

do_runjob() {
	timestamp=$(date +%s)
	input=$HDFS_BASEDIR/corpus-webis-tldr-17.json
	temp_dir=$HDFS_BASEDIR/mapred-TEMP-output
	output_dir=$HDFS_BASEDIR/mapred-output-$timestamp

	# Run job and collect logs & timing
	{ time $HADOOP_DIR/bin/yarn jar $PROJECT_DIR/subredditcount.jar SubredditCount \
		$input $temp_dir $output_dir;
	} 2>&1 | tee job-output-$timestamp.log

	# Remove temporary directory
	$HADOOP_DIR/bin/hdfs dfs -rm -R $temp_dir

	# Copy result from HDFS to local FS
	$HADOOP_DIR/bin/hdfs dfs -get $output_dir/part-r-00000
	mv part-r-00000 mapred-result-$timestamp
	export MY_MAPRED_RESULT=mapred-result-$timestamp
}

main() {
	# Check if no arguments provided or help option requested
	if [[ $# -eq 0 ]] || [[ "$1" == "-h" ]] || [[ "$1" == "--help" ]]; then
		usage
	fi

    # Parse subcommands
    case "$1" in
	    build)
		    shift
		    do_build "$@"
		    ;;
	    start)
		    shift
		    do_start "$@"
		    ;;
	    stop)
		    shift
		    do_stop "$@"
		    ;;

	    runjob)
		    shift
		    do_runjob "$@"
		    ;;
	    *)
		    echo "Error: Unknown subcommand '$1'"
		    usage
		    ;;
    esac
}

main "$@"
